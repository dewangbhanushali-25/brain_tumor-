{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNlz6FSl3wRV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from torchvision.utils import make_grid\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEfDiZ4T3zNi",
        "outputId": "c1687042-ce9d-4a88-f7ae-b62ac14e7d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "oGL_cRt_4HwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BrainTumorDataset(Dataset):\n",
        "  def __init__(self, images, labels):\n",
        "    # images\n",
        "    self.X = images\n",
        "    # labels\n",
        "    self.y = labels\n",
        "\n",
        "    # Transformation for converting original image array to an image and then convert it to a tensor\n",
        "    self.transform = transforms.Compose([transforms.ToPILImage(),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -45 degrees and 45 degrees, and then convert it to a tensor\n",
        "    self.transform1 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomRotation(45),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -90 degrees and 90 degrees, and then convert it to a tensor\n",
        "    self.transform2 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomRotation(90),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -120 degrees and 120 degrees, and then convert it to a tensor\n",
        "    self.transform3 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomRotation(120),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "     # Transformation for converting original image array to an image, rotate it randomly between -180 degrees and 180 degrees, and then convert it to a tensor\n",
        "    self.transform4 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomRotation(180),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -270 degrees and 270 degrees, and then convert it to a tensor\n",
        "    self.transform5 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomRotation(270),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -300 degrees and 300 degrees, and then convert it to a tensor\n",
        "    self.transform6 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomRotation(300),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Transformation for converting original image array to an image, rotate it randomly between -330 degrees and 330 degrees, and then convert it to a tensor\n",
        "    self.transform7 = transforms.Compose([\n",
        "        transforms.ToPILImage(),\n",
        "        transforms.RandomRotation(330),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    # return length of image samples\n",
        "    return len(self.X)\n",
        "  def __getitem__(self, idx):\n",
        "    # perform transformations on one instance of X\n",
        "    # Original image as a tensor\n",
        "    data = self.transform(self.X[idx])\n",
        "\n",
        "    # Augmented image at 45 degrees as a tensor\n",
        "    aug45 = self.transform1(self.X[idx])\n",
        "\n",
        "    # Augmented image at 90 degrees as a tensor\n",
        "    aug90 = self.transform2(self.X[idx])\n",
        "\n",
        "    # Augmented image at 120 degrees as a tensor\n",
        "    aug120 = self.transform3(self.X[idx])\n",
        "\n",
        "    # Augmented image at 180 degrees as a tensor\n",
        "    aug180 = self.transform4(self.X[idx])\n",
        "\n",
        "    # Augmented image at 270 degrees as a tensor\n",
        "    aug270 = self.transform5(self.X[idx])\n",
        "\n",
        "    # Augmented image at 300 degrees as a tensor\n",
        "    aug300 = self.transform6(self.X[idx])\n",
        "\n",
        "    # Augmented image at 330 degrees as a tensor\n",
        "    aug330 = self.transform7(self.X[idx])\n",
        "\n",
        "    # store the transformed images in a list\n",
        "    new_batch = [data, aug45, aug90, aug120, aug180, aug270, aug300, aug330]\n",
        "\n",
        "    # one-hot encode the labels\n",
        "    labels = torch.zeros(4, dtype=torch.float32)\n",
        "    labels[int(self.y[idx])] = 1.0\n",
        "    new_labels = [labels, labels, labels, labels, labels, labels, labels, labels]\n",
        "\n",
        "    # 8 augmented images and corresponding labels per sample will be returned\n",
        "    return (torch.stack(new_labels), torch.stack(new_batch))\n",
        "\n"
      ],
      "metadata": {
        "id": "liXGb5Eg4XVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ZVN8fpPD4y1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import pickle\n",
        "\n",
        "# Load the data using 'rb' mode for binary reading\n",
        "with open('/content/drive/My Drive/Colab Notebooks/new_dataset/training_data.pickle', 'rb') as file:\n",
        "    training_data = pickle.load(file)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "PdbTJhM7SKIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = []\n",
        "yt = []\n",
        "features = None\n",
        "labels = None\n",
        "label = []\n"
      ],
      "metadata": {
        "id": "wQhGnzIl42S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "paUR6-lG5Blz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "daaw-Hg76QE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for features,labels in training_data:\n",
        "  Xt.append(features)\n",
        "  yt.append(labels)\n"
      ],
      "metadata": {
        "id": "hqw3KdGczNOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=0.3, shuffle=True)  # 70% training, 30% testing\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True)  # split testing set into 50% validation , 50% testing\n"
      ],
      "metadata": {
        "id": "CAg0fRlR46Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = None\n",
        "yt = None\n",
        "features = None\n",
        "labels = None\n",
        "label = None\n",
        "training_data = None\n",
        "\n"
      ],
      "metadata": {
        "id": "2z6Kv0UOTmsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = BrainTumorDataset(X_train, y_train)\n",
        "valid_set = BrainTumorDataset(X_valid, y_valid)\n",
        "test_set = BrainTumorDataset(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "FwbextBETpOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of training samples: {len(X_train)}\")\n",
        "print(f\"Number of validation samples: {len(X_valid)}\")\n",
        "print(f\"Number of testing samples: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CY-gGt2TrOD",
        "outputId": "be3cb019-f3bd-4dd2-c037-8ce6eba5ddf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 2144\n",
            "Number of validation samples: 460\n",
            "Number of testing samples: 460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of augmented training samples: {len(X_train) * 8}\")\n",
        "print(f\"Number of augmented validation samples: {len(X_valid)* 8}\")\n",
        "print(f\"Number of augmented testing samples: {len(X_test)* 8}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQUmoghtTuiC",
        "outputId": "b3dc8e78-fa22-470f-d603-d617f1c8b32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of augmented training samples: 17152\n",
            "Number of augmented validation samples: 3680\n",
            "Number of augmented testing samples: 3680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = DataLoader(train_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=8)\n",
        "valid_gen = DataLoader(valid_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=8)\n",
        "test_gen = DataLoader(test_set, batch_size=10, shuffle=True, pin_memory=True, num_workers=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNzI-k7hT-Iu",
        "outputId": "e2d1a1f1-d535-45df-d9e4-851c706b8010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR9nN6X7UDKS",
        "outputId": "b994e5e8-99a2-4186-9fce-9cb32ca7996f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb 25 23:11:01 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "source": [
        "device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\" # Remove the extra colon from \"cuda:0:\"\n",
        "device = torch.device(device_name)\n",
        "print(device)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JFAi0ldYC2h",
        "outputId": "5a040eb0-54a3-4560-e3af-91df769888eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate transfer learning model\n",
        "resnet_model = models.resnet50(pretrained=True)\n",
        "\n",
        "# set all paramters as trainable\n",
        "for param in resnet_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# get input of fc layer\n",
        "n_inputs = resnet_model.fc.in_features\n",
        "\n",
        "# redefine fc layer / top layer/ head for our classification problem\n",
        "resnet_model.fc = nn.Sequential(nn.Linear(n_inputs, 2048),\n",
        "                                nn.SELU(),\n",
        "                                nn.Dropout(p=0.4),\n",
        "                                nn.Linear(2048, 2048),\n",
        "                                nn.SELU(),\n",
        "                                nn.Dropout(p=0.4),\n",
        "                                nn.Linear(2048, 4),\n",
        "                                nn.LogSigmoid())\n",
        "\n",
        "# set all paramters of the model as trainable\n",
        "for name, child in resnet_model.named_children():\n",
        "  for name2, params in child.named_parameters():\n",
        "    params.requires_grad = True\n",
        "\n",
        "# set model to run on GPU or CPU absed on availibility\n",
        "resnet_model.to(device)\n",
        "\n",
        "# print the trasnfer learning NN model's architecture\n",
        "resnet_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZobyB20UGR4",
        "outputId": "c9a89137-378c-406d-9db9-398955d4678d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 170MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "    (1): SELU()\n",
              "    (2): Dropout(p=0.4, inplace=False)\n",
              "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
              "    (4): SELU()\n",
              "    (5): Dropout(p=0.4, inplace=False)\n",
              "    (6): Linear(in_features=2048, out_features=4, bias=True)\n",
              "    (7): LogSigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install neofetch\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "15iOMb9EUJxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!neofetch\n"
      ],
      "metadata": {
        "id": "c9Zn6_3fUUUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "# if GPU is available set loss function to use GPU\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(resnet_model.parameters(), momentum=0.9, lr=3e-4)\n",
        "\n",
        "# number of training iterations\n",
        "epochs = 30\n",
        "\n",
        "# empty lists to store losses and accuracies\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_correct = []\n",
        "test_correct = []"
      ],
      "metadata": {
        "id": "XAteFwJyUon6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, is_best, filename='/content/drive/My Drive/bt_resnet50_ckpt_v2.pth.tar'):\n",
        "    torch.save(state, filename)"
      ],
      "metadata": {
        "id": "Guu46ADuUzYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# set training start time\n",
        "start_time = time.time()\n",
        "\n",
        "# set best_prec loss value as 2 for checkpoint threshold\n",
        "best_prec1 = 2\n",
        "\n",
        "# empty batch variables\n",
        "b = None\n",
        "train_b = None\n",
        "test_b = None\n",
        "\n",
        "# start training\n",
        "for i in range(epochs):\n",
        "    # empty training correct and test correct counter as 0 during every iteration\n",
        "    trn_corr = 0\n",
        "    tst_corr = 0\n",
        "\n",
        "    # set epoch's starting time\n",
        "    e_start = time.time()\n",
        "\n",
        "    # train in batches\n",
        "    for b, (y, X) in enumerate(train_gen):\n",
        "        # set label as cuda if device is cuda\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # forward pass image sample\n",
        "        y_pred = resnet_model(X.view(-1, 3, 512, 512))\n",
        "        # calculate loss\n",
        "        loss = criterion(y_pred.float(), torch.argmax(y.view(32, 4), dim=1).long())\n",
        "\n",
        "        # get argmax of predicted tensor, which is our label\n",
        "        predicted = torch.argmax(y_pred, dim=1).data\n",
        "        # if predicted label is correct as true label, calculate the sum for samples\n",
        "        batch_corr = (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n",
        "        # increment train correct with correcly predicted labels per batch\n",
        "        trn_corr += batch_corr\n",
        "\n",
        "        # set optimizer gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "        # back propagate with loss\n",
        "        loss.backward()\n",
        "        # perform optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "    # set epoch's end time\n",
        "    e_end = time.time()\n",
        "    # print training metrics\n",
        "    print(f'Epoch {(i+1)} Batch {(b+1)*4}\\nAccuracy: {trn_corr.item()*100/(4*8*b):2.2f} %  Loss: {loss.item():2.4f}  Duration: {((e_end-e_start)/60):.2f} minutes') # 4 images per batch * 8 augmentations per image * batch length\n",
        "\n",
        "    # some metrics storage for visualization\n",
        "    train_b = b\n",
        "    train_losses.append(loss)\n",
        "    train_correct.append(trn_corr)\n",
        "\n",
        "    X, y = None, None\n",
        "\n",
        "    # validate using validation generator\n",
        "    # do not perform any gradient updates while validation\n",
        "    with torch.no_grad():\n",
        "        for b, (y, X) in enumerate(valid_gen):\n",
        "            # set label as cuda if device is cuda\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # forward pass image\n",
        "            y_val = resnet_model(X.view(-1, 3, 512, 512))\n",
        "\n",
        "            # get argmax of predicted tensor, which is our label\n",
        "            predicted = torch.argmax(y_val, dim=1).data\n",
        "\n",
        "            # increment test correct with correcly predicted labels per batch\n",
        "            tst_corr += (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n",
        "\n",
        "    # get loss of validation set\n",
        "    loss = criterion(y_val.float(), torch.argmax(y.view(32, 4), dim=1).long())\n",
        "    # print validation metrics\n",
        "    print(f'Validation Accuracy {tst_corr.item()*100/(4*8*b):2.2f} Validation Loss: {loss.item():2.4f}\\n')\n",
        "\n",
        "    # if current validation loss is less than previous iteration's validatin loss create and save a checkpoint\n",
        "    is_best = loss < best_prec1\n",
        "    best_prec1 = min(loss, best_prec1)\n",
        "    save_checkpoint({\n",
        "            'epoch': i + 1,\n",
        "            'state_dict': resnet_model.state_dict(),\n",
        "            'best_prec1': best_prec1,\n",
        "        }, is_best)\n",
        "\n",
        "    # some metrics storage for visualization\n",
        "    test_b  = b\n",
        "    test_losses.append(loss)\n",
        "    test_correct.append(tst_corr)\n",
        "\n",
        "# set total training's end time\n",
        "end_time = time.time() - start_time\n",
        "\n",
        "# print training summary\n",
        "print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
        "print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
        "print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_cached()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmOAlXcuU2dz",
        "outputId": "14c5a20c-2346-45d3-cd5a-35191abfd965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 2144\n",
            "Accuracy: 55.79 %  Loss: 0.2076  Duration: 13.06 minutes\n",
            "Validation Accuracy 76.32 Validation Loss: 0.3480\n",
            "\n",
            "Epoch 2 Batch 2144\n",
            "Accuracy: 78.31 %  Loss: 0.3707  Duration: 13.04 minutes\n",
            "Validation Accuracy 85.47 Validation Loss: 0.4363\n",
            "\n",
            "Epoch 3 Batch 2144\n",
            "Accuracy: 83.90 %  Loss: 0.4651  Duration: 13.05 minutes\n",
            "Validation Accuracy 88.98 Validation Loss: 0.3216\n",
            "\n",
            "Epoch 4 Batch 2144\n",
            "Accuracy: 88.63 %  Loss: 0.4745  Duration: 13.08 minutes\n",
            "Validation Accuracy 89.14 Validation Loss: 0.8763\n",
            "\n",
            "Epoch 5 Batch 2144\n",
            "Accuracy: 89.73 %  Loss: 0.0321  Duration: 13.05 minutes\n",
            "Validation Accuracy 91.26 Validation Loss: 0.9825\n",
            "\n",
            "Epoch 6 Batch 2144\n",
            "Accuracy: 91.29 %  Loss: 0.7108  Duration: 13.06 minutes\n",
            "Validation Accuracy 89.39 Validation Loss: 0.0245\n",
            "\n",
            "Epoch 7 Batch 2144\n",
            "Accuracy: 91.95 %  Loss: 0.0090  Duration: 13.04 minutes\n",
            "Validation Accuracy 93.64 Validation Loss: 0.0157\n",
            "\n",
            "Epoch 8 Batch 2144\n",
            "Accuracy: 94.09 %  Loss: 0.0392  Duration: 13.05 minutes\n",
            "Validation Accuracy 95.50 Validation Loss: 0.0114\n",
            "\n",
            "Epoch 9 Batch 2144\n",
            "Accuracy: 94.88 %  Loss: 0.0612  Duration: 13.09 minutes\n",
            "Validation Accuracy 96.74 Validation Loss: 0.4091\n",
            "\n",
            "Epoch 10 Batch 2144\n",
            "Accuracy: 95.04 %  Loss: 0.5381  Duration: 13.05 minutes\n",
            "Validation Accuracy 96.93 Validation Loss: 0.4361\n",
            "\n",
            "Epoch 11 Batch 2144\n",
            "Accuracy: 96.90 %  Loss: 0.0076  Duration: 13.04 minutes\n",
            "Validation Accuracy 96.74 Validation Loss: 0.1368\n",
            "\n",
            "Epoch 12 Batch 2144\n",
            "Accuracy: 96.79 %  Loss: 0.0029  Duration: 13.04 minutes\n",
            "Validation Accuracy 95.59 Validation Loss: 0.0133\n",
            "\n",
            "Epoch 13 Batch 2144\n",
            "Accuracy: 97.66 %  Loss: 0.0492  Duration: 13.05 minutes\n",
            "Validation Accuracy 95.70 Validation Loss: 0.1673\n",
            "\n",
            "Epoch 14 Batch 2144\n",
            "Accuracy: 97.73 %  Loss: 0.3301  Duration: 13.05 minutes\n",
            "Validation Accuracy 98.60 Validation Loss: 0.0039\n",
            "\n",
            "Epoch 15 Batch 2144\n",
            "Accuracy: 98.72 %  Loss: 0.0608  Duration: 13.07 minutes\n",
            "Validation Accuracy 98.33 Validation Loss: 0.2187\n",
            "\n",
            "Epoch 16 Batch 2144\n",
            "Accuracy: 98.11 %  Loss: 0.0018  Duration: 13.08 minutes\n",
            "Validation Accuracy 98.44 Validation Loss: 0.0291\n",
            "\n",
            "Epoch 17 Batch 2144\n",
            "Accuracy: 98.19 %  Loss: 0.2755  Duration: 13.05 minutes\n",
            "Validation Accuracy 99.04 Validation Loss: 0.0038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(resnet_model.state_dict(), '/content/drive/My Drive/bt_resnet50_model.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "RK2uFjCnQq4u",
        "outputId": "0f829a46-425e-4604-dbc5-6928df2dbc11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'resnet_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a5b5eef16c6c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/My Drive/bt_resnet50_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'resnet_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "VlG7ZfyqVDRh",
        "outputId": "1ec7b14c-33e2-4bf9-d48a-516e2365fea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-18bf08814031>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JzuebVMKWYVK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}